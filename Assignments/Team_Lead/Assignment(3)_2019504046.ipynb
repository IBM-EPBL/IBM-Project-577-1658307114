{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3LGKVYZnrhRN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "metadata": {
        "id": "8groF0LLriW4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Augmentation**"
      ],
      "metadata": {
        "id": "WEShhvuxrlWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug = Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",input_shape=(180, 180, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "U25TrkjrroQv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKHRw8K3rqHL",
        "outputId": "4e592130-381e-4387-9a77-cd89987a8bf3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rzCF4h57rsWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, = tf.keras.utils.image_dataset_from_directory(\n",
        "  \"drive/MyDrive/flowers\",\n",
        "  validation_split=0.25,\n",
        "  subset=\"training\",\n",
        "  seed=132,\n",
        "  image_size=(180, 180),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "bSwjYOWIrt8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.class_names"
      ],
      "metadata": {
        "id": "HBjJrfaJrwFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in train_data.take(1):\n",
        "  for i in range(6):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])"
      ],
      "metadata": {
        "id": "z6kZEuqGrxgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "IVMEOqxvr0pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_normalized = train_data.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(dataset_normalized))\n",
        "first_image = image_batch[0]\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "P18cFOASr1fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model creation and layer addition**"
      ],
      "metadata": {
        "id": "qg96TOXzr24J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  data_aug,\n",
        "  layers.Rescaling(1./255, input_shape=(180, 180, 3)),\n",
        "  # adding convolutional layer\n",
        "  layers.Conv2D(16, 3, activation='relu'),\n",
        "  # adding maxpooling layer\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3,activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  # adding flatten\n",
        "  layers.Flatten(),\n",
        "  # adding dense hidden layer\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  # adding dense output layer\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "7xTJq176r76-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compilation**"
      ],
      "metadata": {
        "id": "KRcfCOnesBlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling model with categorical cross entropy and adam optimizer\n",
        "model.compile(optimizer='adam',\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t9t3-X0ksD64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fitting the Model**"
      ],
      "metadata": {
        "id": "fsWICSUXsF28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=15\n",
        "history = model.fit(train_data,validation_data=val_data,epochs=epochs)"
      ],
      "metadata": {
        "id": "7dZ9OC7ssI5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving**"
      ],
      "metadata": {
        "id": "fwq-62jssMhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"flowers.h5\")"
      ],
      "metadata": {
        "id": "hX10OwJGsQmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('drive/MyDrive/flowers.h5')"
      ],
      "metadata": {
        "id": "Ri-BEPSmsRK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing**"
      ],
      "metadata": {
        "id": "FwXIEetAsSbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sunflower_url = \"https://img.freepik.com/premium-vector/red-rose-with-green-leaf_43623-944.jpg?w=2000\"\n",
        "sunflower_path = tf.keras.utils.get_file('Rose', origin=sunflower_url)\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sunflower_path, target_size=(180, 180)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(class_names[np.argmax(score)],100 * np.max(score))"
      ],
      "metadata": {
        "id": "qhPGI-vLseY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}